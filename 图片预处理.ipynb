{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过三个点计算夹角\n",
    "#b为夹角位置所在的点\n",
    "#默认θ=1计算弧度，θ!不等于1时计算角度\n",
    "def cos_angle(a,b,c,θ = 1):\n",
    "    x,y = b-a,b-c\n",
    "    Lx = np.sqrt(x.dot(x))\n",
    "    Ly = np.sqrt(y.dot(y))\n",
    "    cos_angle = x.dot(y)/(Lx*Ly)\n",
    "    # 根据条件选择是计算弧度还是角度\n",
    "    if θ != 1:\n",
    "        return np.arccos(cos_angle)*360/2/np.pi\n",
    "    else:\n",
    "        return np.arccos(cos_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用人脸标记模型 shape_predictor_68_face_landmarks.dat 标记人脸节点\n",
    "def trait_angle(path):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    landmark_predictor = dlib.shape_predictor(\n",
    "        r'shape_predictor_68_face_landmarks/shape_predictor_68_face_landmarks.dat')\n",
    "    img = cv2.imread(path)\n",
    "    faces = detector(img, 1)\n",
    "    feas = []  # 关键点\n",
    "    if (len(faces) > 0):\n",
    "        for k, d in enumerate(faces):\n",
    "            cv2.rectangle(img, (d.left(), d.top()), (d.right(), d.bottom()), (255, 255, 255))\n",
    "            shape = landmark_predictor(img, d)\n",
    "\n",
    "            for i in range(68):\n",
    "                num = str(shape.part(i))[1:-1].split(\",\")\n",
    "                feas.append([int(num[0]), int(num[1])])\n",
    "\n",
    "    feas = np.array(feas)\n",
    "    s_fa = feas[45, :][1] - feas[36, :][1]\n",
    "    a, b, c = feas[45, :], feas[36, :], np.array(feas[45, :][0], feas[36, :][1])\n",
    "    if abs(s_fa) > 5:\n",
    "        if s_fa > 0 and cos_angle(a, b, c,θ=4) >35:\n",
    "            return cos_angle(a, b, c,θ=4)\n",
    "        elif s_fa < 0 and cos_angle(a, b, c,θ=4) >35:\n",
    "            return 360-cos_angle(a, b, c, θ=4)\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(input,output):\n",
    "    path =input\n",
    "    out_path = output\n",
    "\n",
    "    # 读取图片并识别人脸\n",
    "    img = face_recognition.load_image_file(path)\n",
    "    face_locations = tuple(list(face_recognition.face_locations(img)[0]))\n",
    "\n",
    "    # 重新确定切割位置并切割\n",
    "    top = face_locations[0]\n",
    "    right = face_locations[1]\n",
    "    bottom = face_locations[2]\n",
    "    left = face_locations[3]\n",
    "    cutting_position = (left, top, right, bottom)\n",
    "    # 切割出人脸\n",
    "    im = Image.open(path)\n",
    "\n",
    "    region = im.crop(cutting_position)\n",
    "\n",
    "    # 人脸缩放\n",
    "    a = 50  # 人脸方格大小\n",
    "    if region.size[0] >= a or region.size[1] >= a:\n",
    "        region.thumbnail((a, a), Image.ANTIALIAS)\n",
    "    else:\n",
    "        region = region.resize((a, a), Image.ANTIALIAS)\n",
    "    # 人脸旋转\n",
    "    θ =trait_angle(path)\n",
    "    # region = region.rotate(θ)\n",
    "    # 保存人脸\n",
    "    region.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集地址  最后的斜杆一定不要漏\n",
    "path = 'D:/QIN/Face-classfication/TestDatabase_1/'\n",
    "# 处理后的数据集\n",
    "path_normalization = 'D:/QIN/Face-classfication/TestDatabase_1/normalization/'\n",
    "# 模型保存地址\n",
    "model_path = './人脸识别/model.ckpt'\n",
    "# tfrecord文件存放路径\n",
    "TFRECORD_FILE = \"./人脸识别/tfrecords/\"\n",
    "\n",
    "#全局one-hot编码空间\n",
    "label_binarizer = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试预处理\n",
    "normalization('D:/QIN/Face-classfication/TestDatabase_1/1_1.jpg','D:/QIN/Face-classfication/TestDatabase_1/normalization/11_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取文件批量处理\n",
    "def read_img(path):\n",
    "    map_path, map_relative = [path +x for x in os.listdir(path) if os.path.isfile(path + x) ], [y for y in os.listdir(path)]\n",
    "    return map_path, map_relative\n",
    "\n",
    "# 读取图片并处理保存\n",
    "def read_dispose_img(path):\n",
    "    map_path ,map_relative= read_img(path)\n",
    "    print(map_path)\n",
    "    print(map_relative)\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for idx, folder, in enumerate(map_path):\n",
    "        print(\"读取图并处理中......\"+path_normalization+map_relative[idx])\n",
    "        normalization(folder,path_normalization+map_relative[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/QIN/Face-classfication/TestDatabase_1/10_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/1_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/2_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/3_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/4_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/5_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/6_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/7_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/8_1.jpg', 'D:/QIN/Face-classfication/TestDatabase_1/9_1.jpg']\n",
      "['10_1.jpg', '1_1.jpg', '2_1.jpg', '3_1.jpg', '4_1.jpg', '5_1.jpg', '6_1.jpg', '7_1.jpg', '8_1.jpg', '9_1.jpg', 'normalization']\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/10_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/1_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/2_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/3_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/4_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/5_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/6_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/7_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/8_1.jpg\n",
      "读取图并处理中......D:/QIN/Face-classfication/TestDatabase_1/normalization/9_1.jpg\n"
     ]
    }
   ],
   "source": [
    "#     处理照片\n",
    "read_dispose_img(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#默认按列归一化\n",
    "def def_normalization(x,h = 1):\n",
    "    # 记录归一化全局最大值最小值，回代时需要\n",
    "    if h==1:\n",
    "        #按列归一化\n",
    "        amin, amax = np.min(x, 0), np.max(x, 0)\n",
    "        xx = (x - amin) / (amax - amin)\n",
    "    else:\n",
    "        #按行归一化\n",
    "        amin, amax = np.min(x, 1), np.max(x, 1)\n",
    "        xx = ((x.T - amin) / (amax - amin)).T\n",
    "    #记录归一化最大值最小值，回代时需要\n",
    "    return xx\n",
    "\n",
    "#使用one-hot编码，将离散特征的取值扩展到了欧式空间\n",
    "def def_one_hot(x):\n",
    "    if label_binarizer == \"\":\n",
    "        binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "    else:\n",
    "        binarizer = label_binarizer\n",
    "    binarizer.fit(range(max(x)+1))\n",
    "    y= binarizer.transform(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取处理后的图片，顺序打乱，划分测试和训练  ---》期中C 的文件夹内放置独一无二的类\n",
    "def read_new_img(path):\n",
    "    map_path, map_relative = read_img(path)\n",
    "    imgs=[]\n",
    "    labels=[]\n",
    "    for idx, folder, in enumerate(map_path):\n",
    "        img = io.imread(path_normalization+map_relative[idx])\n",
    "        img = transform.resize(img, (50, 50))\n",
    "        imgs.append(img)\n",
    "        labels.append(int(map_relative[idx].split(\",\")[0].split(\"_\")[0]))\n",
    "    x_data, x_label = np.array(imgs), np.array(labels)\n",
    "    print(\"labels:\")\n",
    "    print(labels)\n",
    "    print(\"x_labels:\")\n",
    "    print(x_label)\n",
    "    print(\"x_data:\")\n",
    "    print(x_data)\n",
    "#     # 打乱顺序\n",
    "#     num_example = data.shape[0]\n",
    "#     arr = np.arange(num_example)\n",
    "#     np.random.shuffle(arr)\n",
    "#     data = data[arr]\n",
    "#     label = label[arr]\n",
    "#     # 将所有数据分为训练集和验证集\n",
    "#     ratio = 0.8\n",
    "#     s = np.int(num_example * ratio)\n",
    "#     return data[:s], data[s:], def_one_hot(label[:s]), def_one_hot(label[s:])\n",
    "    map_path, map_relative = read_img(path + 'c/')\n",
    "    print(map_path)\n",
    "    print(map_relative)\n",
    "    imgs=[]\n",
    "    labels=[]\n",
    "    for idx, folder, in enumerate(map_path):\n",
    "        img = io.imread(path_normalization + 'c/' +map_relative[idx])\n",
    "        img = transform.resize(img, (50, 50))\n",
    "        imgs.append(img)\n",
    "        labels.append(int(map_relative[idx].split(\",\")[0].split(\"_\")[0]))\n",
    "    c_data, c_label = np.array(imgs), np.array(labels)\n",
    "    x_data, c_data, def_one_hot(x_label), def_one_hot(c_label)\n",
    "    return x_data, c_data, def_one_hot(x_label), def_one_hot(c_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####网络层\n",
    "#初始化权值\n",
    "def weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.01)#生成一个截断的正态分布\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "#初始化偏置\n",
    "def bias_variable(shape,name):\n",
    "    initial = tf.constant(0.01,shape=shape)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "#卷积层\n",
    "def conv2d(x,W):\n",
    "    #x input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "    #W filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "    #`strides[0] = strides[3] = 1`. strides[1]代表x方向的步长，strides[2]代表y方向的步长\n",
    "    #padding: A `string` from: `\"SAME\", \"VALID\"`\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "#池化层\n",
    "def max_pool_2x2(x):\n",
    "    #ksize [1,x,y,1]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "#depthwise\n",
    "def tf_depthwise(input,weights ):\n",
    "    depthwise=tf.nn.depthwise_conv2d( input, weights, [1, 1, 1, 1], padding='SAME' ) \n",
    "    return depthwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python conda_py36",
   "language": "python",
   "name": "conda_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
