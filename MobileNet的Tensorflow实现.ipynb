{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\anaconda3.4\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "############################################################################################################\n",
    "# Convolution layer Methods\n",
    "def __conv2d_p(name, x, w=None, num_filters=16, kernel_size=(3, 3), padding='SAME', stride=(1, 1),\n",
    "               initializer=tf.contrib.layers.xavier_initializer(), l2_strength=0.0, bias=0.0):\n",
    "    \"\"\"\n",
    "    Convolution 2D Wrapper\n",
    "    :param name: (string) The name scope provided by the upper tf.name_scope('name') as scope.\n",
    "    :param x: (tf.tensor) The input to the layer (N, H, W, C).\n",
    "    :param w: (tf.tensor) pretrained weights (if None, it means no pretrained weights)\n",
    "    :param num_filters: (integer) No. of filters (This is the output depth)\n",
    "    :param kernel_size: (integer tuple) The size of the convolving kernel.\n",
    "    :param padding: (string) The amount of padding required.\n",
    "    :param stride: (integer tuple) The stride required.\n",
    "    :param initializer: (tf.contrib initializer) The initialization scheme, He et al. normal or Xavier normal are recommended.\n",
    "    :param l2_strength:(weight decay) (float) L2 regularization parameter.\n",
    "    :param bias: (float) Amount of bias. (if not float, it means pretrained bias)\n",
    "    :return out: The output of the layer. (N, H', W', num_filters)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        stride = [1, stride[0], stride[1], 1]\n",
    "        kernel_shape = [kernel_size[0], kernel_size[1], x.shape[-1], num_filters]\n",
    "\n",
    "        with tf.name_scope('layer_weights'):\n",
    "            if w == None:\n",
    "                w = __variable_with_weight_decay(kernel_shape, initializer, l2_strength)\n",
    "            __variable_summaries(w)\n",
    "        with tf.name_scope('layer_biases'):\n",
    "            if isinstance(bias, float):\n",
    "                bias = tf.get_variable('biases', [num_filters], initializer=tf.constant_initializer(bias))\n",
    "            __variable_summaries(bias)\n",
    "        with tf.name_scope('layer_conv2d'):\n",
    "            conv = tf.nn.conv2d(x, w, stride, padding)\n",
    "            out = tf.nn.bias_add(conv, bias)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def conv2d(name, x, w=None, num_filters=16, kernel_size=(3, 3), padding='SAME', stride=(1, 1),\n",
    "           initializer=tf.contrib.layers.xavier_initializer(), l2_strength=0.0, bias=0.0,\n",
    "           activation=None, batchnorm_enabled=False, max_pool_enabled=False, dropout_keep_prob=-1,\n",
    "           is_training=True):\n",
    "    \"\"\"\n",
    "    This block is responsible for a convolution 2D layer followed by optional (non-linearity, dropout, max-pooling).\n",
    "    Note that: \"is_training\" should be passed by a correct value based on being in either training or testing.\n",
    "    :param name: (string) The name scope provided by the upper tf.name_scope('name') as scope.\n",
    "    :param x: (tf.tensor) The input to the layer (N, H, W, C).\n",
    "    :param num_filters: (integer) No. of filters (This is the output depth)\n",
    "    :param kernel_size: (integer tuple) The size of the convolving kernel.\n",
    "    :param padding: (string) The amount of padding required.\n",
    "    :param stride: (integer tuple) The stride required.\n",
    "    :param initializer: (tf.contrib initializer) The initialization scheme, He et al. normal or Xavier normal are recommended.\n",
    "    :param l2_strength:(weight decay) (float) L2 regularization parameter.\n",
    "    :param bias: (float) Amount of bias.\n",
    "    :param activation: (tf.graph operator) The activation function applied after the convolution operation. If None, linear is applied.\n",
    "    :param batchnorm_enabled: (boolean) for enabling batch normalization.\n",
    "    :param max_pool_enabled:  (boolean) for enabling max-pooling 2x2 to decrease width and height by a factor of 2.\n",
    "    :param dropout_keep_prob: (float) for the probability of keeping neurons. If equals -1, it means no dropout\n",
    "    :param is_training: (boolean) to diff. between training and testing (important for batch normalization and dropout)\n",
    "    :return: The output tensor of the layer (N, H', W', C').\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        conv_o_b = __conv2d_p(scope, x=x, w=w, num_filters=num_filters, kernel_size=kernel_size, stride=stride,\n",
    "                              padding=padding,\n",
    "                              initializer=initializer, l2_strength=l2_strength, bias=bias)\n",
    "\n",
    "        if batchnorm_enabled:\n",
    "            conv_o_bn = tf.layers.batch_normalization(conv_o_b, training=is_training)\n",
    "            if not activation:\n",
    "                conv_a = conv_o_bn\n",
    "            else:\n",
    "                conv_a = activation(conv_o_bn)\n",
    "        else:\n",
    "            if not activation:\n",
    "                conv_a = conv_o_b\n",
    "            else:\n",
    "                conv_a = activation(conv_o_b)\n",
    "\n",
    "        def dropout_with_keep():\n",
    "            return tf.nn.dropout(conv_a, dropout_keep_prob)\n",
    "\n",
    "        def dropout_no_keep():\n",
    "            return tf.nn.dropout(conv_a, 1.0)\n",
    "\n",
    "        if dropout_keep_prob != -1:\n",
    "            conv_o_dr = tf.cond(is_training, dropout_with_keep, dropout_no_keep)\n",
    "        else:\n",
    "            conv_o_dr = conv_a\n",
    "\n",
    "        conv_o = conv_o_dr\n",
    "        if max_pool_enabled:\n",
    "            conv_o = max_pool_2d(conv_o_dr)\n",
    "\n",
    "    return conv_o\n",
    "\n",
    "\n",
    "def __depthwise_conv2d_p(name, x, w=None, kernel_size=(3, 3), padding='SAME', stride=(1, 1),\n",
    "                         initializer=tf.contrib.layers.xavier_initializer(), l2_strength=0.0, bias=0.0):\n",
    "    with tf.variable_scope(name):\n",
    "        stride = [1, stride[0], stride[1], 1]\n",
    "        kernel_shape = [kernel_size[0], kernel_size[1], x.shape[-1], 1]\n",
    "\n",
    "        with tf.name_scope('layer_weights'):\n",
    "            if w is None:\n",
    "                w = __variable_with_weight_decay(kernel_shape, initializer, l2_strength)\n",
    "            __variable_summaries(w)\n",
    "        with tf.name_scope('layer_biases'):\n",
    "            if isinstance(bias, float):\n",
    "                bias = tf.get_variable('biases', [x.shape[-1]], initializer=tf.constant_initializer(bias))\n",
    "            __variable_summaries(bias)\n",
    "        with tf.name_scope('layer_conv2d'):\n",
    "            conv = tf.nn.depthwise_conv2d(x, w, stride, padding)\n",
    "            out = tf.nn.bias_add(conv, bias)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def depthwise_conv2d(name, x, w=None, kernel_size=(3, 3), padding='SAME', stride=(1, 1),\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(), l2_strength=0.0, bias=0.0, activation=None,\n",
    "                     batchnorm_enabled=False, is_training=True):\n",
    "    \"\"\"Implementation of depthwise 2D convolution wrapper\"\"\"\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        conv_o_b = __depthwise_conv2d_p(name=scope, x=x, w=w, kernel_size=kernel_size, padding=padding,\n",
    "                                        stride=stride, initializer=initializer, l2_strength=l2_strength, bias=bias)\n",
    "\n",
    "        if batchnorm_enabled:\n",
    "            conv_o_bn = tf.layers.batch_normalization(conv_o_b, training=is_training)\n",
    "            if not activation:\n",
    "                conv_a = conv_o_bn\n",
    "            else:\n",
    "                conv_a = activation(conv_o_bn)\n",
    "        else:\n",
    "            if not activation:\n",
    "                conv_a = conv_o_b\n",
    "            else:\n",
    "                conv_a = activation(conv_o_b)\n",
    "    return conv_a\n",
    "\n",
    "\n",
    "def depthwise_separable_conv2d(name, x, w_depthwise=None, w_pointwise=None, width_multiplier=1.0, num_filters=16,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding='SAME', stride=(1, 1),\n",
    "                               initializer=tf.contrib.layers.xavier_initializer(), l2_strength=0.0, biases=(0.0, 0.0),\n",
    "                               activation=None, batchnorm_enabled=True,\n",
    "                               is_training=True):\n",
    "    \"\"\"Implementation of depthwise separable 2D convolution operator as in MobileNet paper\"\"\"\n",
    "    total_num_filters = int(round(num_filters * width_multiplier))\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        conv_a = depthwise_conv2d('depthwise', x=x, w=w_depthwise, kernel_size=kernel_size, padding=padding,\n",
    "                                  stride=stride,\n",
    "                                  initializer=initializer, l2_strength=l2_strength, bias=biases[0],\n",
    "                                  activation=activation,\n",
    "                                  batchnorm_enabled=batchnorm_enabled, is_training=is_training)\n",
    "\n",
    "        conv_o = conv2d('pointwise', x=conv_a, w=w_pointwise, num_filters=total_num_filters, kernel_size=(1, 1),\n",
    "                        initializer=initializer, l2_strength=l2_strength, bias=biases[1], activation=activation,\n",
    "                        batchnorm_enabled=batchnorm_enabled, is_training=is_training)\n",
    "\n",
    "    return conv_a, conv_o\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "# Fully Connected layer Methods\n",
    "\n",
    "def __dense_p(name, x, w=None, output_dim=128, initializer=tf.contrib.layers.xavier_initializer(), l2_strength=0.0,\n",
    "              bias=0.0):\n",
    "    \"\"\"\n",
    "    Fully connected layer\n",
    "    :param name: (string) The name scope provided by the upper tf.name_scope('name') as scope.\n",
    "    :param x: (tf.tensor) The input to the layer (N, D).\n",
    "    :param output_dim: (integer) It specifies H, the output second dimension of the fully connected layer [ie:(N, H)]\n",
    "    :param initializer: (tf.contrib initializer) The initialization scheme, He et al. normal or Xavier normal are recommended.\n",
    "    :param l2_strength:(weight decay) (float) L2 regularization parameter.\n",
    "    :param bias: (float) Amount of bias. (if not float, it means pretrained bias)\n",
    "    :return out: The output of the layer. (N, H)\n",
    "    \"\"\"\n",
    "    n_in = x.get_shape()[-1].value\n",
    "    with tf.variable_scope(name):\n",
    "        if w == None:\n",
    "            w = __variable_with_weight_decay([n_in, output_dim], initializer, l2_strength)\n",
    "        __variable_summaries(w)\n",
    "        if isinstance(bias, float):\n",
    "            bias = tf.get_variable(\"layer_biases\", [output_dim], tf.float32, tf.constant_initializer(bias))\n",
    "        __variable_summaries(bias)\n",
    "        output = tf.nn.bias_add(tf.matmul(x, w), bias)\n",
    "        return output\n",
    "\n",
    "\n",
    "def dense(name, x, w=None, output_dim=128, initializer=tf.contrib.layers.xavier_initializer(), l2_strength=0.0,\n",
    "          bias=0.0,\n",
    "          activation=None, batchnorm_enabled=False, dropout_keep_prob=-1,\n",
    "          is_training=True\n",
    "          ):\n",
    "    \"\"\"\n",
    "    This block is responsible for a fully connected followed by optional (non-linearity, dropout, max-pooling).\n",
    "    Note that: \"is_training\" should be passed by a correct value based on being in either training or testing.\n",
    "    :param name: (string) The name scope provided by the upper tf.name_scope('name') as scope.\n",
    "    :param x: (tf.tensor) The input to the layer (N, D).\n",
    "    :param output_dim: (integer) It specifies H, the output second dimension of the fully connected layer [ie:(N, H)]\n",
    "    :param initializer: (tf.contrib initializer) The initialization scheme, He et al. normal or Xavier normal are recommended.\n",
    "    :param l2_strength:(weight decay) (float) L2 regularization parameter.\n",
    "    :param bias: (float) Amount of bias.\n",
    "    :param activation: (tf.graph operator) The activation function applied after the convolution operation. If None, linear is applied.\n",
    "    :param batchnorm_enabled: (boolean) for enabling batch normalization.\n",
    "    :param dropout_keep_prob: (float) for the probability of keeping neurons. If equals -1, it means no dropout\n",
    "    :param is_training: (boolean) to diff. between training and testing (important for batch normalization and dropout)\n",
    "    :return out: The output of the layer. (N, H)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        dense_o_b = __dense_p(name=scope, x=x, w=w, output_dim=output_dim, initializer=initializer,\n",
    "                              l2_strength=l2_strength,\n",
    "                              bias=bias)\n",
    "\n",
    "        if batchnorm_enabled:\n",
    "            dense_o_bn = tf.layers.batch_normalization(dense_o_b, training=is_training)\n",
    "            if not activation:\n",
    "                dense_a = dense_o_bn\n",
    "            else:\n",
    "                dense_a = activation(dense_o_bn)\n",
    "        else:\n",
    "            if not activation:\n",
    "                dense_a = dense_o_b\n",
    "            else:\n",
    "                dense_a = activation(dense_o_b)\n",
    "\n",
    "        def dropout_with_keep():\n",
    "            return tf.nn.dropout(dense_a, dropout_keep_prob)\n",
    "\n",
    "        def dropout_no_keep():\n",
    "            return tf.nn.dropout(dense_a, 1.0)\n",
    "\n",
    "        if dropout_keep_prob != -1:\n",
    "            dense_o_dr = tf.cond(is_training, dropout_with_keep, dropout_no_keep)\n",
    "        else:\n",
    "            dense_o_dr = dense_a\n",
    "\n",
    "        dense_o = dense_o_dr\n",
    "    return dense_o\n",
    "\n",
    "\n",
    "def dropout(x, dropout_keep_prob, is_training):\n",
    "    \"\"\"Dropout special layer\"\"\"\n",
    "\n",
    "    def dropout_with_keep():\n",
    "        return tf.nn.dropout(x, dropout_keep_prob)\n",
    "\n",
    "    def dropout_no_keep():\n",
    "        return tf.nn.dropout(x, 1.0)\n",
    "\n",
    "    if dropout_keep_prob != -1:\n",
    "        output = tf.cond(is_training, dropout_with_keep, dropout_no_keep)\n",
    "    else:\n",
    "        output = x\n",
    "    return output\n",
    "\n",
    "\n",
    "def flatten(x):\n",
    "    \"\"\"\n",
    "    Flatten a (N,H,W,C) input into (N,D) output. Used for fully connected layers after conolution layers\n",
    "    :param x: (tf.tensor) representing input\n",
    "    :return: flattened output\n",
    "    \"\"\"\n",
    "    all_dims_exc_first = np.prod([v.value for v in x.get_shape()[1:]])\n",
    "    o = tf.reshape(x, [-1, all_dims_exc_first])\n",
    "    return o\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "# Pooling Methods\n",
    "\n",
    "def max_pool_2d(x, size=(2, 2), stride=(2, 2), name='pooling'):\n",
    "    \"\"\"\n",
    "    Max pooling 2D Wrapper\n",
    "    :param x: (tf.tensor) The input to the layer (N,H,W,C).\n",
    "    :param size: (tuple) This specifies the size of the filter as well as the stride.\n",
    "    :param stride: (tuple) specifies the stride of pooling.\n",
    "    :param name: (string) Scope name.\n",
    "    :return: The output is the same input but halfed in both width and height (N,H/2,W/2,C).\n",
    "    \"\"\"\n",
    "    size_x, size_y = size\n",
    "    stride_x, stride_y = stride\n",
    "    return tf.nn.max_pool(x, ksize=[1, size_x, size_y, 1], strides=[1, stride_x, stride_y, 1], padding='VALID',\n",
    "                          name=name)\n",
    "\n",
    "\n",
    "def avg_pool_2d(x, size=(2, 2), stride=(2, 2), name='avg_pooling'):\n",
    "    \"\"\"\n",
    "        Average pooling 2D Wrapper\n",
    "        :param x: (tf.tensor) The input to the layer (N,H,W,C).\n",
    "        :param size: (tuple) This specifies the size of the filter as well as the stride.\n",
    "        :param name: (string) Scope name.\n",
    "        :return: The output is the same input but halfed in both width and height (N,H/2,W/2,C).\n",
    "    \"\"\"\n",
    "    size_x, size_y = size\n",
    "    stride_x, stride_y = stride\n",
    "    return tf.nn.avg_pool(x, ksize=[1, size_x, size_y, 1], strides=[1, stride_x, stride_y, 1], padding='VALID',\n",
    "                          name=name)\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "# Utilities for layers\n",
    "\n",
    "def __variable_with_weight_decay(kernel_shape, initializer, wd):\n",
    "    \"\"\"\n",
    "    Create a variable with L2 Regularization (Weight Decay)\n",
    "    :param kernel_shape: the size of the convolving weight kernel.\n",
    "    :param initializer: The initialization scheme, He et al. normal or Xavier normal are recommended.\n",
    "    :param wd:(weight decay) L2 regularization parameter.\n",
    "    :return: The weights of the kernel initialized. The L2 loss is added to the loss collection.\n",
    "    \"\"\"\n",
    "    w = tf.get_variable('weights', kernel_shape, tf.float32, initializer=initializer)\n",
    "\n",
    "    collection_name = tf.GraphKeys.REGULARIZATION_LOSSES\n",
    "    if wd and (not tf.get_variable_scope().reuse):\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(w), wd, name='w_loss')\n",
    "        tf.add_to_collection(collection_name, weight_decay)\n",
    "    return w\n",
    "\n",
    "\n",
    "# Summaries for variables\n",
    "def __variable_summaries(var):\n",
    "    \"\"\"\n",
    "    Attach a lot of summaries to a Tensor (for TensorBoard visualization).\n",
    "    :param var: variable to be summarized\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_obj(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#外部参数\n",
    "experiment_dir = \"test_experiment\"\n",
    "num_epochs = 100\n",
    "num_classes = 1001\n",
    "batch_size = 1\n",
    "width_multiplier = 1.0\n",
    "shuffle = True\n",
    "l2_strength = 4e-5\n",
    "bias = np.float64(0)\n",
    "learning_rate = 1e-3\n",
    "batchnorm_enabled = True\n",
    "dropout_keep_prob = 0.999\n",
    "pretrained_path = \"pretrained_weights/mobilenet_v1.pkl\"\n",
    "max_to_keep = 4\n",
    "save_model_every = 5\n",
    "test_every = 5\n",
    "to_train = True\n",
    "to_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init parameters and input\n",
    "X = None\n",
    "y = None\n",
    "logits = None\n",
    "is_training = None\n",
    "loss = None\n",
    "regularization_loss = None\n",
    "cross_entropy_loss = None\n",
    "train_op = None\n",
    "accuracy = None\n",
    "y_out_argmax = None\n",
    "summaries_merged = None\n",
    "# mean_img = None\n",
    "nodes = dict()\n",
    "\n",
    "pretrained_path = os.path.realpath(pretrained_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据集地址  最后的斜杆一定不要漏\n",
    "path = 'D:/QIN/Face-classfication/TestDatabase_1/'\n",
    "# 处理后的数据集\n",
    "path_normalization = 'D:/QIN/Face-classfication/TestDatabase_2/'\n",
    "# 模型保存地址\n",
    "model_path = './人脸识别/model.ckpt'\n",
    "# tfrecord文件存放路径\n",
    "TFRECORD_FILE = \"./人脸识别/tfrecords/\"\n",
    "\n",
    "#全局one-hot编码空间\n",
    "label_binarizer = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    map_path, map_relative = [path +x for x in os.listdir(path) if os.path.isfile(path + x) ], [y for y in os.listdir(path)]\n",
    "    return map_path, map_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#默认按列归一化\n",
    "def def_normalization(x,h = 1):\n",
    "    # 记录归一化全局最大值最小值，回代时需要\n",
    "    if h==1:\n",
    "        #按列归一化\n",
    "        amin, amax = np.min(x, 0), np.max(x, 0)\n",
    "        xx = (x - amin) / (amax - amin)\n",
    "    else:\n",
    "        #按行归一化\n",
    "        amin, amax = np.min(x, 1), np.max(x, 1)\n",
    "        xx = ((x.T - amin) / (amax - amin)).T\n",
    "    #记录归一化最大值最小值，回代时需要\n",
    "    return xx\n",
    "\n",
    "#使用one-hot编码，将离散特征的取值扩展到了欧式空间\n",
    "def def_one_hot(x):\n",
    "    if label_binarizer == \"\":\n",
    "        binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "    else:\n",
    "        binarizer = label_binarizer\n",
    "    binarizer.fit(x)\n",
    "    y= binarizer.transform(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取处理后的图片，顺序打乱，划分测试和训练\n",
    "def read_new_img(path):\n",
    "    map_path, map_relative = read_img(path)\n",
    "    imgs=[]\n",
    "    labels=[]\n",
    "    for idx, folder, in enumerate(map_path):\n",
    "        if map_relative[idx].split(\".\")[0] == 'train' or map_relative[idx].split(\".\")[0] == 'test':\n",
    "            continue\n",
    "        img = io.imread(path_normalization+map_relative[idx])\n",
    "        img = transform.resize(img, (224, 224))\n",
    "        imgs.append(img)\n",
    "        if map_relative[idx].split(\".\")[0].split(\"_\")[1].isdigit():\n",
    "            la_name = map_relative[idx].split(\".\")[0].split(\"_\")[0]\n",
    "            labels.append(la_name)\n",
    "        else:\n",
    "            la_name = map_relative[idx].split(\".\")[0].split(\"_\")[0] + '_'+map_relative[idx].split(\".\")[0].split(\"_\")[1]\n",
    "            labels.append(la_name)\n",
    "    x_data, x_label = np.array(imgs), np.array(def_one_hot(np.array(labels)))\n",
    "    data = []\n",
    "    sigle_data = []\n",
    "    for i in range(len(x_data)):\n",
    "        sigle_data.append(x_data[i])\n",
    "        sigle_data.append(x_label[i])\n",
    "        data.append(sigle_data)\n",
    "        sigle_data = []\n",
    "        # 打乱顺序\n",
    "    data = np.array(data)\n",
    "    num_example = data.shape[0]\n",
    "    np.random.shuffle(data)\n",
    "    # 将所有数据分为训练集和验证集\n",
    "    ratio = 0.8\n",
    "    img_train = []\n",
    "    label_train = []\n",
    "    img_test = []\n",
    "    label_test = []\n",
    "    for i in range(int(ratio*num_example)):\n",
    "        img_train.append(data[i][0])\n",
    "        label_train.append(data[i][1])\n",
    "    img_train = np.array(img_train)\n",
    "    label_train = np.array(label_train)\n",
    "    for i in range(int(ratio*num_example),num_example):\n",
    "        img_test.append(data[i][0])\n",
    "        label_test.append(data[i][1])\n",
    "    img_test = np.array(img_test)\n",
    "    label_test = np.array(label_test)\n",
    "    print(img_train)\n",
    "    return img_train,img_test,label_train,label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init_global_epoch():\n",
    "    \"\"\"\n",
    "    Create a global epoch tensor to totally save the process of the training\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('global_epoch'):\n",
    "        global_epoch_tensor = tf.Variable(-1, trainable=False, name='global_epoch')\n",
    "        global_epoch_input = tf.placeholder('int32', None, name='global_epoch_input')\n",
    "        global_epoch_assign_op = global_epoch_tensor.assign(global_epoch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init_global_step():\n",
    "    \"\"\"\n",
    "    Create a global step variable to be a reference to the number of iterations\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('global_step'):\n",
    "        global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
    "        global_step_input = tf.placeholder('int32', None, name='global_step_input')\n",
    "        global_step_assign_op = global_step_tensor.assign(global_step_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init_mean():\n",
    "    # Preparing the mean image.\n",
    "    img_mean = np.ones((1, 224, 224, 3))\n",
    "    img_mean[:, :, :, 0] *= 103.939\n",
    "    img_mean[:, :, :, 1] *= 116.779\n",
    "    img_mean[:, :, :, 2] *= 123.68\n",
    "    mean_img = tf.constant(img_mean, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init_input():\n",
    "    with tf.variable_scope('input'):\n",
    "        # Input images\n",
    "        X = tf.placeholder(tf.float32,\n",
    "                                [None, 224, 224,3])\n",
    "        # Classification supervision, it's an argmax. Feel free to change it to one-hot,\n",
    "        # but don't forget to change the loss from sparse as well\n",
    "        y = tf.placeholder(tf.float32, [None,num_classes])   ### <---------------------------注意一下\n",
    "        # is_training is for batch normalization and dropout, if they exist\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "        # 改变x的格式转为4D的向量[batch, in_height, in_width, in_channels]`\n",
    "        X = tf.reshape(X, [-1, 224, 224, 3], name='x_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __add_to_nodes(nodes):\n",
    "    for node in nodes:\n",
    "        nodes[node.name] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def __init_network():\n",
    "    x_train, x_test, y_train, y_test = read_new_img(path_normalization)\n",
    "    m,n = y_train.shape\n",
    "    print(\"m:\")\n",
    "    print(m)\n",
    "    print(\"n:\")\n",
    "    print(n)\n",
    "    num_classes = n\n",
    "    with tf.variable_scope('global_epoch'):\n",
    "        global_epoch_tensor = tf.Variable(-1, trainable=False, name='global_epoch')\n",
    "        global_epoch_input = tf.placeholder('int32', None, name='global_epoch_input')\n",
    "        global_epoch_assign_op = global_epoch_tensor.assign(global_epoch_input)\n",
    "    with tf.variable_scope('global_step'):\n",
    "        global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
    "        global_step_input = tf.placeholder('int32', None, name='global_step_input')\n",
    "        global_step_assign_op = global_step_tensor.assign(global_step_input)\n",
    "\n",
    "    with tf.variable_scope('input'):\n",
    "        # Input images\n",
    "        X = tf.placeholder(tf.float32,\n",
    "                                [None, 224, 224,3])\n",
    "        # Classification supervision, it's an argmax. Feel free to change it to one-hot,\n",
    "        # but don't forget to change the loss from sparse as well\n",
    "        y = tf.placeholder(tf.float32, [None,num_classes])   ### <---------------------------注意一下\n",
    "        # is_training is for batch normalization and dropout, if they exist\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "        # 改变x的格式转为4D的向量[batch, in_height, in_width, in_channels]`\n",
    "        X = tf.reshape(X, [-1, 224, 224, 3], name='x_image')\n",
    "    with tf.variable_scope('mobilenet_encoder'):\n",
    "        # Preprocessing as done in the paper\n",
    "        with tf.name_scope('pre_processing'):\n",
    "            # Preparing the mean image.\n",
    "#             img_mean = np.ones((1, 224, 224, 3))\n",
    "#             img_mean[:, :, :, 0] *= 103.939\n",
    "#             img_mean[:, :, :, 1] *= 116.779\n",
    "#             img_mean[:, :, :, 2] *= 123.68\n",
    "#             mean_img = tf.constant(img_mean, dtype=tf.float32)\n",
    "#             preprocessed_input = (X - mean_img) / 255.0\n",
    "            preprocessed_input = tf.cast(X,dtype=tf.float32)\n",
    "        # Model is here!\n",
    "        preprocessed_input = tf.cast(X,dtype=tf.float32)\n",
    "        print(preprocessed_input)\n",
    "        conv1_1 = conv2d('conv_1', preprocessed_input, num_filters=int(round(32 * width_multiplier)),\n",
    "                             kernel_size=(3, 3),\n",
    "                             padding='SAME', stride=(2, 2), activation=tf.nn.relu6,\n",
    "                             batchnorm_enabled=batchnorm_enabled,\n",
    "                             is_training=is_training, l2_strength=l2_strength, bias=bias)\n",
    "#         __add_to_nodes([conv1_1])\n",
    "        ############################################################################################\n",
    "        print(conv1_1)\n",
    "        conv2_1_dw, conv2_1_pw = depthwise_separable_conv2d('conv_ds_2', conv1_1,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=64, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv2_1_dw, conv2_1_pw])\n",
    "        print(conv2_1_pw)\n",
    "        conv2_2_dw, conv2_2_pw = depthwise_separable_conv2d('conv_ds_3', conv2_1_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=128, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(2, 2),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv2_2_dw, conv2_2_pw])\n",
    "        print(conv2_2_pw)\n",
    "        ############################################################################################\n",
    "        conv3_1_dw, conv3_1_pw = depthwise_separable_conv2d('conv_ds_4', conv2_2_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=128, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv3_1_dw, conv3_1_pw])\n",
    "        print(conv3_1_pw)\n",
    "        conv3_2_dw, conv3_2_pw = depthwise_separable_conv2d('conv_ds_5', conv3_1_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=256, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(2, 2),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv3_2_dw, conv3_2_pw])\n",
    "        print(conv3_2_pw)\n",
    "        ############################################################################################\n",
    "        conv4_1_dw, conv4_1_pw = depthwise_separable_conv2d('conv_ds_6', conv3_2_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=256, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv4_1_dw, conv4_1_pw])\n",
    "        print(conv4_1_pw)\n",
    "        conv4_2_dw, conv4_2_pw = depthwise_separable_conv2d('conv_ds_7', conv4_1_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=512, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(2, 2),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv4_2_dw, conv4_2_pw])\n",
    "        print(conv4_2_pw)\n",
    "        ############################################################################################\n",
    "        conv5_1_dw, conv5_1_pw = depthwise_separable_conv2d('conv_ds_8', conv4_2_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=512, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv5_1_dw, conv5_1_pw])\n",
    "        print(conv5_1_pw)\n",
    "        conv5_2_dw, conv5_2_pw = depthwise_separable_conv2d('conv_ds_9', conv5_1_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=512, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv5_2_dw, conv5_2_pw])\n",
    "        print(conv5_2_pw)\n",
    "        conv5_3_dw, conv5_3_pw = depthwise_separable_conv2d('conv_ds_10', conv5_2_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=512, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv5_3_dw, conv5_3_pw])\n",
    "        print(conv5_3_pw)\n",
    "        conv5_4_dw, conv5_4_pw = depthwise_separable_conv2d('conv_ds_11', conv5_3_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=512, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv5_4_dw, conv5_4_pw])\n",
    "        print(conv5_4_pw)\n",
    "        conv5_5_dw, conv5_5_pw = depthwise_separable_conv2d('conv_ds_12', conv5_4_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=512, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv5_5_dw, conv5_5_pw])\n",
    "        print(conv5_5_pw)\n",
    "        conv5_6_dw, conv5_6_pw = depthwise_separable_conv2d('conv_ds_13', conv5_5_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=1024, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(2, 2),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv5_6_dw, conv5_6_pw])\n",
    "        print(conv5_6_pw)\n",
    "        ############################################################################################\n",
    "        conv6_1_dw, conv6_1_pw = depthwise_separable_conv2d('conv_ds_14', conv5_6_pw,\n",
    "                                                                width_multiplier=width_multiplier,\n",
    "                                                                num_filters=1024, kernel_size=(3, 3), padding='SAME',\n",
    "                                                                stride=(1, 1),\n",
    "                                                                batchnorm_enabled=batchnorm_enabled,\n",
    "                                                                activation=tf.nn.relu6,\n",
    "                                                                is_training=is_training,\n",
    "                                                                l2_strength=l2_strength,\n",
    "                                                                biases=(bias, bias))\n",
    "#         __add_to_nodes([conv6_1_dw, conv6_1_pw])\n",
    "        print(conv6_1_pw)\n",
    "        ############################################################################################\n",
    "        avg_pool = avg_pool_2d(conv6_1_pw, size=(7, 7), stride=(1, 1),name=\"avg_pool\")\n",
    "        print(avg_pool)\n",
    "        dropped = tf.nn.dropout(avg_pool, dropout_keep_prob)\n",
    "        print(dropped)\n",
    "#         dropped = dropout(avg_pool, 0.999, is_training)\n",
    "        logits = flatten(conv2d('fc', dropped, kernel_size=(1, 1), num_filters=num_classes,\n",
    "                                         l2_strength=l2_strength,\n",
    "                                         bias=bias))\n",
    "        print(logits)\n",
    "#         return logits\n",
    "#         __add_to_nodes([avg_pool, dropped, logits])\n",
    "    with tf.variable_scope('output'):\n",
    "        regularization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "        cross_entropy_loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=tf.argmax(tf.cast(y, dtype=tf.int32),1), name='loss'))\n",
    "        loss = regularization_loss + cross_entropy_loss\n",
    "\n",
    "        # Important for Batch Normalization\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "            y_out_argmax = tf.argmax(tf.nn.softmax(logits), axis=-1, output_type=tf.int64)\n",
    "\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tf.cast(y,dtype=tf.int64), -1), y_out_argmax), tf.float32))\n",
    "\n",
    "        # Summaries needed for TensorBoard\n",
    "        with tf.name_scope('train-summary-per-iteration'):\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            tf.summary.scalar('acc', accuracy)\n",
    "            summaries_merged = tf.summary.merge_all()\n",
    "    #保存模型使用环境\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # 创建一个协调器，管理线程\n",
    "        coord = tf.train.Coordinator()\n",
    "        # 启动QueueRunner, 此时文件名队列已经进队\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        for i in range(20):\n",
    "            # 训练模型\n",
    "            sess.run(train_op, feed_dict={X: x_train, y: y_train,is_training:True})\n",
    "\n",
    "            test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test,is_training:True})\n",
    "            train_acc = sess.run(accuracy, feed_dict={X: x_train, y: y_train,is_training:True})\n",
    "            print(\"训练第 \" + str(i) + \" 次, 训练集准确率= \" + str(train_acc) + \" , 测试集准确率= \" + str(test_acc))\n",
    "\n",
    "            if test_acc == 1 and train_acc >= 0.95:\n",
    "                print(\"准确率完爆了\")\n",
    "                # 保存模型\n",
    "                saver.save(sess, 'nn/my_net.ckpt')\n",
    "                break\n",
    "\n",
    "        # 通知其他线程关闭\n",
    "        coord.request_stop()\n",
    "        # 其他所有线程关闭之后，这一函数才能返回\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def __init_output(logits):\n",
    "    with tf.variable_scope('output'):\n",
    "        regularization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "        cross_entropy_loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=tf.argmax(tf.cast(y, dtype=tf.int32),1), name='loss'))\n",
    "        loss = regularization_loss + cross_entropy_loss\n",
    "\n",
    "        # Important for Batch Normalization\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "            y_out_argmax = tf.argmax(tf.nn.softmax(logits), axis=-1, output_type=tf.int64)\n",
    "\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tf.cast(y,dtype=tf.int64), -1), y_out_argmax), tf.float32))\n",
    "\n",
    "        # Summaries needed for TensorBoard\n",
    "        with tf.name_scope('train-summary-per-iteration'):\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            tf.summary.scalar('acc', accuracy)\n",
    "            summaries_merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __train():\n",
    "    #保存模型使用环境\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # 创建一个协调器，管理线程\n",
    "        coord = tf.train.Coordinator()\n",
    "        # 启动QueueRunner, 此时文件名队列已经进队\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        for i in range(50):\n",
    "            # 训练模型\n",
    "            sess.run(train_op, feed_dict={X: x_train, y: y_train, keep_prob: 0.9})\n",
    "\n",
    "            test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test, keep_prob: 1.0})\n",
    "            train_acc = sess.run(accuracy, feed_dict={X: x_train, y: y_train, keep_prob: 1.0})\n",
    "            print(\"训练第 \" + str(i) + \" 次, 训练集准确率= \" + str(train_acc) + \" , 测试集准确率= \" + str(test_acc))\n",
    "\n",
    "            if test_acc == 1 and train_acc >= 0.95:\n",
    "                print(\"准确率完爆了\")\n",
    "                # 保存模型\n",
    "                saver.save(sess, 'nn/my_net.ckpt')\n",
    "                break\n",
    "\n",
    "        # 通知其他线程关闭\n",
    "        coord.request_stop()\n",
    "        # 其他所有线程关闭之后，这一函数才能返回\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __build():\n",
    "#     __init_global_epoch()\n",
    "#     __init_global_step()\n",
    "#     __init_mean()\n",
    "#     __init_input()\n",
    "#     logits = __init_network()\n",
    "    __init_network()\n",
    "#     __init_output(logits)\n",
    "#     __train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\anaconda3.4\\envs\\py36\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.30588235 0.3372549  0.28627451]\n",
      "   [0.30588235 0.3372549  0.28627451]\n",
      "   [0.30980392 0.34117647 0.29019608]\n",
      "   ...\n",
      "   [0.19215686 0.19607843 0.14117647]\n",
      "   [0.21176471 0.21568627 0.16078431]\n",
      "   [0.22352941 0.22352941 0.17647059]]\n",
      "\n",
      "  [[0.30588235 0.3372549  0.28627451]\n",
      "   [0.30588235 0.3372549  0.28627451]\n",
      "   [0.30980392 0.34117647 0.29019608]\n",
      "   ...\n",
      "   [0.19607843 0.2        0.14509804]\n",
      "   [0.21176471 0.21568627 0.16078431]\n",
      "   [0.21960784 0.22352941 0.16862745]]\n",
      "\n",
      "  [[0.30588235 0.3372549  0.28627451]\n",
      "   [0.30588235 0.3372549  0.28627451]\n",
      "   [0.31372549 0.34509804 0.29411765]\n",
      "   ...\n",
      "   [0.19607843 0.2        0.14509804]\n",
      "   [0.21176471 0.21568627 0.16078431]\n",
      "   [0.21960784 0.22352941 0.16862745]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.87058824 0.87843137 0.85882353]\n",
      "   [0.87058824 0.87843137 0.85882353]\n",
      "   [0.8745098  0.87843137 0.85882353]\n",
      "   ...\n",
      "   [0.4627451  0.36078431 0.27058824]\n",
      "   [0.46666667 0.36470588 0.2745098 ]\n",
      "   [0.47058824 0.36862745 0.27843137]]\n",
      "\n",
      "  [[0.86666667 0.8745098  0.85490196]\n",
      "   [0.86666667 0.8745098  0.85490196]\n",
      "   [0.87058824 0.8745098  0.85490196]\n",
      "   ...\n",
      "   [0.46666667 0.36470588 0.2745098 ]\n",
      "   [0.47058824 0.36862745 0.27843137]\n",
      "   [0.4745098  0.37254902 0.28235294]]\n",
      "\n",
      "  [[0.86666667 0.8745098  0.85490196]\n",
      "   [0.86666667 0.8745098  0.85490196]\n",
      "   [0.87058824 0.8745098  0.85490196]\n",
      "   ...\n",
      "   [0.47058824 0.36862745 0.27843137]\n",
      "   [0.4745098  0.37254902 0.28235294]\n",
      "   [0.47843137 0.37647059 0.28627451]]]\n",
      "\n",
      "\n",
      " [[[0.18823529 0.16862745 0.19215686]\n",
      "   [0.19215686 0.17254902 0.18823529]\n",
      "   [0.19607843 0.17647059 0.19215686]\n",
      "   ...\n",
      "   [0.23529412 0.16078431 0.09411765]\n",
      "   [0.24313725 0.16862745 0.10196078]\n",
      "   [0.24313725 0.16862745 0.10196078]]\n",
      "\n",
      "  [[0.19215686 0.17254902 0.19607843]\n",
      "   [0.19215686 0.17254902 0.19607843]\n",
      "   [0.19607843 0.17647059 0.19215686]\n",
      "   ...\n",
      "   [0.23137255 0.15686275 0.09019608]\n",
      "   [0.23921569 0.16470588 0.09803922]\n",
      "   [0.24313725 0.16862745 0.10196078]]\n",
      "\n",
      "  [[0.19215686 0.17254902 0.19607843]\n",
      "   [0.19607843 0.17647059 0.2       ]\n",
      "   [0.2        0.18039216 0.19607843]\n",
      "   ...\n",
      "   [0.22745098 0.15294118 0.08627451]\n",
      "   [0.23529412 0.16078431 0.09411765]\n",
      "   [0.23529412 0.16078431 0.09411765]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.49019608 0.47843137 0.45882353]\n",
      "   [0.50588235 0.49411765 0.4745098 ]\n",
      "   [0.58039216 0.56078431 0.54509804]\n",
      "   ...\n",
      "   [0.09019608 0.09019608 0.1372549 ]\n",
      "   [0.09019608 0.09019608 0.1372549 ]\n",
      "   [0.09019608 0.09019608 0.1372549 ]]\n",
      "\n",
      "  [[0.49019608 0.48627451 0.46666667]\n",
      "   [0.50196078 0.49803922 0.47843137]\n",
      "   [0.57254902 0.56078431 0.54117647]\n",
      "   ...\n",
      "   [0.09019608 0.09019608 0.1372549 ]\n",
      "   [0.09019608 0.09019608 0.1372549 ]\n",
      "   [0.09019608 0.09019608 0.1372549 ]]\n",
      "\n",
      "  [[0.49411765 0.49019608 0.4745098 ]\n",
      "   [0.49803922 0.49411765 0.4745098 ]\n",
      "   [0.56078431 0.54901961 0.52941176]\n",
      "   ...\n",
      "   [0.09019608 0.09019608 0.1372549 ]\n",
      "   [0.09019608 0.09019608 0.1372549 ]\n",
      "   [0.09019608 0.09019608 0.1372549 ]]]\n",
      "\n",
      "\n",
      " [[[0.17254902 0.09803922 0.10588235]\n",
      "   [0.15686275 0.08235294 0.09019608]\n",
      "   [0.1372549  0.0627451  0.07058824]\n",
      "   ...\n",
      "   [0.27843137 0.2627451  0.25098039]\n",
      "   [0.2745098  0.25882353 0.24705882]\n",
      "   [0.29411765 0.2745098  0.2627451 ]]\n",
      "\n",
      "  [[0.19607843 0.12156863 0.12941176]\n",
      "   [0.17647059 0.10196078 0.10980392]\n",
      "   [0.15686275 0.08235294 0.09019608]\n",
      "   ...\n",
      "   [0.29411765 0.27843137 0.26666667]\n",
      "   [0.28627451 0.27058824 0.25882353]\n",
      "   [0.29411765 0.2745098  0.2627451 ]]\n",
      "\n",
      "  [[0.21568627 0.14117647 0.14901961]\n",
      "   [0.19607843 0.12156863 0.12941176]\n",
      "   [0.17254902 0.09803922 0.10588235]\n",
      "   ...\n",
      "   [0.3254902  0.30980392 0.29803922]\n",
      "   [0.30196078 0.28627451 0.2745098 ]\n",
      "   [0.29411765 0.2745098  0.2627451 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.15294118 0.21568627 0.31764706]\n",
      "   [0.16078431 0.22352941 0.3254902 ]\n",
      "   [0.17254902 0.23529412 0.3372549 ]\n",
      "   ...\n",
      "   [0.1254902  0.19215686 0.29411765]\n",
      "   [0.12941176 0.19607843 0.29803922]\n",
      "   [0.12941176 0.19607843 0.29803922]]\n",
      "\n",
      "  [[0.16470588 0.22745098 0.32941176]\n",
      "   [0.16862745 0.23137255 0.33333333]\n",
      "   [0.18039216 0.24313725 0.34509804]\n",
      "   ...\n",
      "   [0.12156863 0.18823529 0.29019608]\n",
      "   [0.1254902  0.19215686 0.29411765]\n",
      "   [0.12941176 0.19607843 0.29803922]]\n",
      "\n",
      "  [[0.17254902 0.23529412 0.3372549 ]\n",
      "   [0.17647059 0.23921569 0.34117647]\n",
      "   [0.18431373 0.24705882 0.34901961]\n",
      "   ...\n",
      "   [0.11764706 0.18431373 0.28627451]\n",
      "   [0.1254902  0.19215686 0.29411765]\n",
      "   [0.12941176 0.19607843 0.29803922]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.74117647 0.80392157 0.76078431]\n",
      "   [0.74509804 0.80784314 0.76470588]\n",
      "   [0.73333333 0.79607843 0.75294118]\n",
      "   ...\n",
      "   [0.16862745 0.20392157 0.23137255]\n",
      "   [0.15686275 0.19215686 0.21960784]\n",
      "   [0.14901961 0.18431373 0.21176471]]\n",
      "\n",
      "  [[0.74509804 0.80784314 0.76470588]\n",
      "   [0.74901961 0.81176471 0.76862745]\n",
      "   [0.7372549  0.8        0.75686275]\n",
      "   ...\n",
      "   [0.16470588 0.2        0.22745098]\n",
      "   [0.15294118 0.18823529 0.21568627]\n",
      "   [0.14509804 0.18039216 0.20784314]]\n",
      "\n",
      "  [[0.75294118 0.81568627 0.77254902]\n",
      "   [0.75294118 0.81568627 0.77254902]\n",
      "   [0.74117647 0.80392157 0.76078431]\n",
      "   ...\n",
      "   [0.15686275 0.19215686 0.21960784]\n",
      "   [0.14509804 0.18039216 0.20784314]\n",
      "   [0.14117647 0.17647059 0.20392157]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7254902  0.76862745 0.78431373]\n",
      "   [0.7254902  0.76862745 0.78431373]\n",
      "   [0.72156863 0.76470588 0.78823529]\n",
      "   ...\n",
      "   [0.28627451 0.45490196 0.58823529]\n",
      "   [0.28235294 0.45098039 0.58431373]\n",
      "   [0.28235294 0.45098039 0.58431373]]\n",
      "\n",
      "  [[0.71372549 0.75686275 0.77254902]\n",
      "   [0.71372549 0.75686275 0.77254902]\n",
      "   [0.71372549 0.75686275 0.77254902]\n",
      "   ...\n",
      "   [0.28235294 0.45098039 0.58431373]\n",
      "   [0.27843137 0.44705882 0.58039216]\n",
      "   [0.27843137 0.44705882 0.58039216]]\n",
      "\n",
      "  [[0.69803922 0.74117647 0.75686275]\n",
      "   [0.70196078 0.74509804 0.76078431]\n",
      "   [0.70588235 0.74901961 0.76470588]\n",
      "   ...\n",
      "   [0.28235294 0.45098039 0.58431373]\n",
      "   [0.27843137 0.44705882 0.58039216]\n",
      "   [0.2745098  0.44313725 0.57647059]]]\n",
      "\n",
      "\n",
      " [[[0.18823529 0.24313725 0.19215686]\n",
      "   [0.20392157 0.25490196 0.21568627]\n",
      "   [0.23529412 0.28627451 0.24705882]\n",
      "   ...\n",
      "   [0.52156863 0.36862745 0.06666667]\n",
      "   [0.52156863 0.36862745 0.05882353]\n",
      "   [0.52156863 0.36862745 0.05882353]]\n",
      "\n",
      "  [[0.18431373 0.23921569 0.18823529]\n",
      "   [0.20392157 0.25490196 0.21568627]\n",
      "   [0.23529412 0.28627451 0.24705882]\n",
      "   ...\n",
      "   [0.52156863 0.36862745 0.06666667]\n",
      "   [0.52156863 0.36862745 0.05882353]\n",
      "   [0.52156863 0.36862745 0.05882353]]\n",
      "\n",
      "  [[0.17254902 0.22352941 0.18431373]\n",
      "   [0.19607843 0.24705882 0.20784314]\n",
      "   [0.22745098 0.27843137 0.23921569]\n",
      "   ...\n",
      "   [0.52156863 0.36862745 0.06666667]\n",
      "   [0.52156863 0.36862745 0.05882353]\n",
      "   [0.52156863 0.36862745 0.05882353]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7372549  0.59607843 0.29019608]\n",
      "   [0.7372549  0.59607843 0.29019608]\n",
      "   [0.7372549  0.6        0.27843137]\n",
      "   ...\n",
      "   [0.5372549  0.38039216 0.10588235]\n",
      "   [0.5372549  0.38039216 0.10588235]\n",
      "   [0.5372549  0.38039216 0.10588235]]\n",
      "\n",
      "  [[0.7372549  0.59607843 0.29803922]\n",
      "   [0.7372549  0.59607843 0.29019608]\n",
      "   [0.7372549  0.6        0.28235294]\n",
      "   ...\n",
      "   [0.5372549  0.38039216 0.10588235]\n",
      "   [0.5372549  0.38039216 0.10588235]\n",
      "   [0.5372549  0.38039216 0.10588235]]\n",
      "\n",
      "  [[0.7372549  0.59607843 0.29803922]\n",
      "   [0.7372549  0.59607843 0.29019608]\n",
      "   [0.7372549  0.6        0.28235294]\n",
      "   ...\n",
      "   [0.5372549  0.38039216 0.10588235]\n",
      "   [0.5372549  0.38039216 0.10588235]\n",
      "   [0.5372549  0.38039216 0.10588235]]]\n",
      "\n",
      "\n",
      " [[[0.83921569 0.63137255 0.50588235]\n",
      "   [0.83921569 0.63137255 0.50588235]\n",
      "   [0.83921569 0.63137255 0.50588235]\n",
      "   ...\n",
      "   [0.20392157 0.1372549  0.0745098 ]\n",
      "   [0.18431373 0.12156863 0.05882353]\n",
      "   [0.18039216 0.11764706 0.05490196]]\n",
      "\n",
      "  [[0.83921569 0.63137255 0.50588235]\n",
      "   [0.83921569 0.63137255 0.50588235]\n",
      "   [0.83921569 0.63137255 0.50588235]\n",
      "   ...\n",
      "   [0.20392157 0.1372549  0.0745098 ]\n",
      "   [0.18431373 0.12156863 0.05882353]\n",
      "   [0.18039216 0.11764706 0.05490196]]\n",
      "\n",
      "  [[0.83137255 0.63529412 0.50588235]\n",
      "   [0.83137255 0.63529412 0.50588235]\n",
      "   [0.83137255 0.63529412 0.50588235]\n",
      "   ...\n",
      "   [0.20392157 0.1372549  0.0745098 ]\n",
      "   [0.18431373 0.12156863 0.05882353]\n",
      "   [0.17647059 0.11372549 0.05098039]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.49019608 0.42352941 0.30588235]\n",
      "   [0.45882353 0.39215686 0.2745098 ]\n",
      "   [0.43529412 0.36078431 0.24313725]\n",
      "   ...\n",
      "   [0.1254902  0.11764706 0.16862745]\n",
      "   [0.1254902  0.11764706 0.16862745]\n",
      "   [0.1254902  0.11764706 0.16862745]]\n",
      "\n",
      "  [[0.51372549 0.43921569 0.32156863]\n",
      "   [0.48235294 0.40784314 0.28235294]\n",
      "   [0.44313725 0.36862745 0.24313725]\n",
      "   ...\n",
      "   [0.12941176 0.12156863 0.17254902]\n",
      "   [0.12941176 0.12156863 0.17254902]\n",
      "   [0.1254902  0.11764706 0.16862745]]\n",
      "\n",
      "  [[0.52156863 0.44705882 0.32156863]\n",
      "   [0.48627451 0.41176471 0.28627451]\n",
      "   [0.44705882 0.37254902 0.24705882]\n",
      "   ...\n",
      "   [0.12941176 0.12156863 0.17254902]\n",
      "   [0.12941176 0.12156863 0.17254902]\n",
      "   [0.12941176 0.12156863 0.17254902]]]]\n",
      "m:\n",
      "69\n",
      "n:\n",
      "42\n",
      "Tensor(\"input/x_image:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_1/Relu6:0\", shape=(?, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_2/pointwise/Relu6:0\", shape=(?, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_3/pointwise/Relu6:0\", shape=(?, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_4/pointwise/Relu6:0\", shape=(?, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_5/pointwise/Relu6:0\", shape=(?, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_6/pointwise/Relu6:0\", shape=(?, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_7/pointwise/Relu6:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_8/pointwise/Relu6:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_9/pointwise/Relu6:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_10/pointwise/Relu6:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_11/pointwise/Relu6:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_12/pointwise/Relu6:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_13/pointwise/Relu6:0\", shape=(?, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/conv_ds_14/pointwise/Relu6:0\", shape=(?, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/avg_pool:0\", shape=(?, 1, 1, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/dropout/mul:0\", shape=(?, 1, 1, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_encoder/Reshape:0\", shape=(?, 42), dtype=float32)\n",
      "训练第 0 次, 训练集准确率= 0.17391305 , 测试集准确率= 0.055555556\n",
      "训练第 1 次, 训练集准确率= 0.24637681 , 测试集准确率= 0.055555556\n",
      "训练第 2 次, 训练集准确率= 0.28985506 , 测试集准确率= 0.11111111\n",
      "训练第 3 次, 训练集准确率= 0.3478261 , 测试集准确率= 0.16666667\n",
      "训练第 4 次, 训练集准确率= 0.44927537 , 测试集准确率= 0.11111111\n",
      "训练第 5 次, 训练集准确率= 0.5507246 , 测试集准确率= 0.16666667\n",
      "训练第 6 次, 训练集准确率= 0.7246377 , 测试集准确率= 0.16666667\n",
      "训练第 7 次, 训练集准确率= 0.884058 , 测试集准确率= 0.16666667\n",
      "训练第 8 次, 训练集准确率= 0.98550725 , 测试集准确率= 0.16666667\n",
      "训练第 9 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 10 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 11 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 12 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 13 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 14 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 15 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 16 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 17 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 18 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n",
      "训练第 19 次, 训练集准确率= 1.0 , 测试集准确率= 0.16666667\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    __build()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python conda_py36",
   "language": "python",
   "name": "conda_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
